import Foundation
import AVFoundation
import SwiftUI

@MainActor
class AudioManager: NSObject, ObservableObject, AVAudioPlayerDelegate {
    
    // MARK: - Published Properties
    @Published var isPlayingAudio: Bool = false
    @Published var currentAudioFile: String = ""
    @Published var audioProgress: Float = 0.0
    
    // MARK: - Private Properties
    private var audioPlayer: AVAudioPlayer?
    private var onCompletionCallback: (() -> Void)?
    private var progressTimer: Timer?
    
    // MARK: - Audio Session Setup
    override init() {
        super.init()
        // ì´ˆê¸°í™” ì‹œì—ëŠ” ì˜¤ë””ì˜¤ ì„¸ì…˜ì„ ì„¤ì •í•˜ì§€ ì•ŠìŒ
        // ì‹¤ì œ ìž¬ìƒ ì‹œì—ë§Œ ì„¤ì •
        checkAvailableAudioFiles()
    }
    
    // âœ… ìœ ì—°í•œ ì˜¤ë””ì˜¤ ì„¸ì…˜ ì„¤ì •
    private func setupAudioSessionIfNeeded() -> Bool {
        let coordinator = AudioSessionCoordinator.shared
        
        // ì´ë¯¸ ì ì ˆí•œ ëª¨ë“œê°€ í™œì„±í™”ë˜ì–´ ìžˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        if coordinator.currentAudioMode == .geminiLiveAudio || 
           coordinator.currentAudioMode == .audioPlayback {
            print("ðŸŽµ AudioManager: Using existing audio session mode: \(coordinator.currentAudioMode)")
            return true
        }
        
        // í•„ìš”í•œ ê²½ìš°ì—ë§Œ ì˜¤ë””ì˜¤ ì„¸ì…˜ ìš”ì²­
        if coordinator.requestAudioSession(for: .audioPlayback) {
            print("âœ… AudioManager: Audio session acquired")
            return true
        } else {
            // ì‹¤íŒ¨ ì‹œ ì§ì ‘ ì„¤ì • ì‹œë„
            do {
                let audioSession = AVAudioSession.sharedInstance()
                try audioSession.setCategory(.playAndRecord,
                                            mode: .default,
                                            options: [.defaultToSpeaker, .mixWithOthers])
                try audioSession.setActive(true)
                print("ðŸ”„ AudioManager: Direct audio session setup successful")
                return true
            } catch {
                print("âŒ AudioManager: Audio session setup failed: \(error)")
                // ì—ëŸ¬ê°€ ë°œìƒí•´ë„ ê³„ì† ì§„í–‰
                return false
            }
        }
    }
    
    // MARK: - Main Audio Playback Methods
    
    /// ê¸°ë³¸ ì˜¤ë””ì˜¤ íŒŒì¼ ìž¬ìƒ
    func playAudioFile(_ filename: String, onComplete: (() -> Void)? = nil) {
        print("AudioManager: Playing audio file: \(filename)")
        
        guard let url = Bundle.main.url(forResource: filename.replacingOccurrences(of: ".wav", with: ""), withExtension: "wav") else {
            print("AudioManager: âŒ Audio file not found: \(filename)")
            print("AudioManager: âŒ CRITICAL ERROR - Audio file missing. Please add to Xcode project.")
            
            // âŒ TTS ì œê±° - ì˜¤ë””ì˜¤ íŒŒì¼ì´ ì—†ìœ¼ë©´ ì—ëŸ¬ ì²˜ë¦¬ë§Œ
            onComplete?()
            return
        }
        
        stopAudio() // ê¸°ì¡´ ì˜¤ë””ì˜¤ ì¤‘ì§€
        
        // í•„ìš”í•œ ê²½ìš°ì—ë§Œ ì˜¤ë””ì˜¤ ì„¸ì…˜ ì„¤ì •
        if !setupAudioSessionIfNeeded() {
            print("AudioManager: âš ï¸ Audio session not available, attempting playback anyway")
        }
        
        do {
            audioPlayer = try AVAudioPlayer(contentsOf: url)
            audioPlayer?.delegate = self
            audioPlayer?.prepareToPlay()
            
            // ì¶”ê°€ ë³¼ë¥¨ ë¶€ìŠ¤íŠ¸ ì„¤ì •
            audioPlayer?.enableRate = true
            audioPlayer?.volume = 1.0  // ìµœëŒ€ ë³¼ë¥¨ (ê³µì‹ ë²”ìœ„: 0.0~1.0)
            
            // ì‹œìŠ¤í…œ ë³¼ë¥¨ì„ ìµœëŒ€ë¡œ ì„¤ì • ì‹œë„
            do {
                try AVAudioSession.sharedInstance().setActive(true)
                try AVAudioSession.sharedInstance().overrideOutputAudioPort(.speaker)
            } catch {
                print("AudioManager: âš ï¸ Failed to override audio port: \(error)")
            }
            
            isPlayingAudio = true
            currentAudioFile = filename
            onCompletionCallback = onComplete
            
            startProgressTimer()
            audioPlayer?.play()
            
            print("AudioManager: ðŸ“¢ Volume set to \(audioPlayer?.volume ?? 0.0) (Max: 1.0)")
            print("AudioManager: ðŸ”Š Audio output forced to speaker")
            
            print("AudioManager: âœ… Started playing \(filename)")
            
        } catch {
            print("AudioManager: âŒ Failed to play audio: \(error)")
            isPlayingAudio = false
            onComplete?()
        }
    }
    
    // MARK: - Progress Tracking
    
    private func startProgressTimer() {
        progressTimer?.invalidate()
        progressTimer = Timer.scheduledTimer(withTimeInterval: 0.1, repeats: true) { [weak self] _ in
            Task { @MainActor in
                self?.updateProgress()
            }
        }
    }
    
    private func updateProgress() {
        guard let player = audioPlayer, player.isPlaying else {
            stopProgressTimer()
            return
        }
        
        if player.duration > 0 {
            audioProgress = Float(player.currentTime / player.duration)
        }
    }
    
    private func stopProgressTimer() {
        progressTimer?.invalidate()
        progressTimer = nil
        audioProgress = 0.0
    }
    
    // MARK: - Audio Control
    
    func stopAudio() {
        audioPlayer?.stop()
        audioPlayer = nil
        stopProgressTimer()
        
        isPlayingAudio = false
        currentAudioFile = ""
        
        // ì˜¤ë””ì˜¤ ì„¸ì…˜ í•´ì œ (ë‹¤ë¥¸ ì•±ì´ ì‚¬ìš©í•  ìˆ˜ ìžˆë„ë¡)
        AudioSessionCoordinator.shared.releaseAudioSession(for: .audioPlayback)
        
        print("AudioManager: Audio stopped")
    }
    
    func pauseAudio() {
        audioPlayer?.pause()
        stopProgressTimer()
        print("AudioManager: Audio paused")
    }
    
    func resumeAudio() {
        audioPlayer?.play()
        startProgressTimer()
        print("AudioManager: Audio resumed")
    }
    
    // MARK: - AVAudioPlayerDelegate
    
    nonisolated func audioPlayerDidFinishPlaying(_ player: AVAudioPlayer, successfully flag: Bool) {
        print("AudioManager: Audio finished playing successfully: \(flag)")
        Task { @MainActor in
            self.handleAudioCompletion()
        }
    }
    
    nonisolated func audioPlayerDecodeErrorDidOccur(_ player: AVAudioPlayer, error: Error?) {
        print("AudioManager: âŒ Audio decode error: \(String(describing: error))")
        Task { @MainActor in
            self.handleAudioCompletion()
        }
    }
    
    // MARK: - Completion Handling
    
    private func handleAudioCompletion() {
        stopProgressTimer()
        
        isPlayingAudio = false
        currentAudioFile = ""
        
        let callback = onCompletionCallback
        onCompletionCallback = nil
        
        print("AudioManager: âœ… Audio completion detected, calling callback")
        callback?()
    }
    
    // MARK: - Utility Methods
    
    /// ì‚¬ìš© ê°€ëŠ¥í•œ ì˜¤ë””ì˜¤ íŒŒì¼ ëª©ë¡ í™•ì¸
    func checkAvailableAudioFiles() {
        let requiredFiles = [
            "welcome_rotate_360.wav",
            "ask_what_object.wav", 
            "object_not_found.wav",
            "object_found_haptic_guide.wav",
            "target_locked_distance.wav",
            "target_reached_final.wav"
        ]
        
        print("AudioManager: Checking required audio files...")
        for filename in requiredFiles {
            let baseFilename = filename.replacingOccurrences(of: ".wav", with: "")
            if Bundle.main.url(forResource: baseFilename, withExtension: "wav") != nil {
                print("âœ… Found: \(filename)")
            } else {
                print("âŒ Missing: \(filename)")
            }
        }
    }
    
    deinit {
        progressTimer?.invalidate()
        audioPlayer?.stop()
        
        // ì˜¤ë””ì˜¤ ì„¸ì…˜ í•´ì œ
        Task { @MainActor in
            AudioSessionCoordinator.shared.releaseAudioSession(for: .audioPlayback)
        }
    }
}

// MARK: - Predefined Audio Files
extension AudioManager {
    
    /// Stage 1 ì§„ìž…ì‹œ í™˜ì˜ ë° íšŒì „ ì•ˆë‚´
    func playWelcomeRotateAudio(onComplete: (() -> Void)? = nil) {
        playAudioFile("welcome_rotate_360.wav", onComplete: onComplete)
    }
    
    /// 360ë„ íšŒì „ ì™„ë£Œ í›„ ê°ì²´ ë¬¸ì˜
    func playAskObjectAudio(onComplete: (() -> Void)? = nil) {
        playAudioFile("ask_what_object.wav", onComplete: onComplete)
    }
    
    /// ê°ì²´ë¥¼ ì°¾ì§€ ëª»í–ˆì„ ë•Œ
    func playObjectNotFoundAudio(onComplete: (() -> Void)? = nil) {
        playAudioFile("object_not_found.wav", onComplete: onComplete)
    }
    
    /// ê°ì²´ ë°œê²¬ ë° í–…í‹± ê°€ì´ë“œ ì‹œìž‘
    func playObjectFoundHapticGuideAudio(onComplete: (() -> Void)? = nil) {
        playAudioFile("object_found_haptic_guide.wav", onComplete: onComplete)
    }
    
    /// íƒ€ê²Ÿ ë½ì˜¨ ë° Stage 2 ì§„ìž…
    func playTargetLockedAudio(distance: Float, onComplete: (() -> Void)? = nil) {
        playAudioFile("target_locked_distance.wav", onComplete: onComplete)
    }
    
    /// íƒ€ê²Ÿ ë„ë‹¬ ë° Stage 3 ì§„ìž…
    func playTargetReachedAudio(distance: Float, onComplete: (() -> Void)? = nil) {
        playAudioFile("target_reached_final.wav", onComplete: onComplete)
    }
} 